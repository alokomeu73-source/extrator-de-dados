# app.py (VERS√ÉO 8 - COM ANALISTA DE IA INTEGRADO)

# ==============================================================================
# 1Ô∏è‚É£ CONFIGURA√á√ÉO E IMPORTA√á√ïES
# ==============================================================================
import streamlit as st
import pandas as pd
import fitz  # PyMuPDF
import pytesseract
from PIL import Image, ImageEnhance, ImageFilter
import re
import io
from datetime import datetime

# Configura√ß√£o da p√°gina do Streamlit
st.set_page_config(
    page_title="Extrator de Guias M√©dicas com IA",
    page_icon="ü§ñ",
    layout="wide"
)

# Verifica se o Tesseract est√° instalado
try:
    pytesseract.get_tesseract_version()
except pytesseract.TesseractNotFoundError:
    st.error(
        "Tesseract OCR n√£o foi encontrado. "
        "Certifique-se de que o Tesseract OCR est√° instalado e acess√≠vel no PATH do sistema."
    )
    st.stop()

# ==============================================================================
# 2Ô∏è‚É£ FUN√á√ïES DE PROCESSAMENTO DE ARQUIVO E OCR (ESTRUTURADO)
# ==============================================================================

def preprocess_image(image):
    """Aplica pr√©-processamento para melhorar a qualidade do OCR."""
    img = image.convert('L')  # Converte para escala de cinza
    enhancer = ImageEnhance.Contrast(img)
    img = enhancer.enhance(2.0) # Aumenta o contraste
    img = img.filter(ImageFilter.SHARPEN) # Aplica nitidez
    return img

def extract_text_from_image(image: Image.Image):
    """
    Extrai texto e suas coordenadas de um objeto de imagem PIL usando Tesseract.
    Retorna um DataFrame do Pandas com dados estruturados.
    """
    processed_image = preprocess_image(image)
    # Usa image_to_data para obter texto, coordenadas e confian√ßa
    ocr_df = pytesseract.image_to_data(
        processed_image,
        lang='por',
        output_type=pytesseract.Output.DATAFRAME
    )
    # Filtra palavras vazias ou com baixa confian√ßa
    ocr_df.dropna(subset=['text'], inplace=True)
    ocr_df = ocr_df[ocr_df['conf'] > 30]
    ocr_df['text'] = ocr_df['text'].str.strip()
    ocr_df = ocr_df[ocr_df['text'] != '']
    return ocr_df

def process_uploaded_file(uploaded_file):
    """
    Processa um arquivo enviado (imagem ou PDF), convertendo-o para um
    DataFrame OCR estruturado. PDFs s√£o rasterizados para imagens.
    """
    file_bytes = io.BytesIO(uploaded_file.read())
    file_name = uploaded_file.name

    try:
        if uploaded_file.type == "application/pdf":
            # Processamento de PDF: converte a primeira p√°gina em imagem
            pdf_document = fitz.open(stream=file_bytes, filetype="pdf")
            page = pdf_document.load_page(0)
            pix = page.get_pixmap(dpi=300)
            image = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            pdf_document.close()
            return extract_text_from_image(image)
        else:
            # Processamento de Imagem
            image = Image.open(file_bytes)
            return extract_text_from_image(image)
    except Exception as e:
        st.error(f"Erro ao processar o arquivo '{file_name}': {e}")
        return pd.DataFrame()


# ==============================================================================
# 3Ô∏è‚É£ L√ìGICA DE EXTRA√á√ÉO BASEADA EM COORDENADAS (SEM ALTERA√á√ïES)
# ==============================================================================

def find_value_near_label(ocr_df, label_pattern, max_distance_x=500):
    """
    Encontra o valor √† direita de um r√≥tulo com base em sua posi√ß√£o.
    """
    try:
        # Encontra a(s) parte(s) do r√≥tulo
        label_rows = ocr_df[ocr_df['text'].str.contains(label_pattern, na=False, flags=re.IGNORECASE)]
        if label_rows.empty:
            return "N√£o encontrado"

        # Pega as coordenadas da primeira ocorr√™ncia do r√≥tulo
        label_row = label_rows.iloc[0]
        label_x = label_row['left'] + label_row['width']
        label_y_center = label_row['top'] + label_row['height'] / 2

        # Define a √°rea de busca para o valor (mesma linha, √† direita)
        search_top = label_y_center - label_row['height']
        search_bottom = label_y_center + label_row['height']
        search_left = label_x
        search_right = label_x + max_distance_x

        # Filtra as palavras candidatas que est√£o na √°rea de busca
        value_df = ocr_df[
            (ocr_df['top'] >= search_top) &
            (ocr_df['top'] <= search_bottom) &
            (ocr_df['left'] >= search_left) &
            (ocr_df['left'] <= search_right)
        ]

        if value_df.empty:
            return "N√£o encontrado"

        # Ordena as palavras por sua posi√ß√£o horizontal e junta o texto
        value_df = value_df.sort_values(by='left')
        found_value = ' '.join(value_df['text'].astype(str))

        return found_value.strip()

    except Exception:
        return "N√£o encontrado"

def extract_medical_data_from_structure(ocr_df):
    """Fun√ß√£o principal que orquestra a extra√ß√£o usando a l√≥gica espacial."""
    if ocr_df.empty:
        return {
            "N√∫mero GUIA": "OCR falhou", "Registro ANS": "OCR falhou",
            "Data de Autoriza√ß√£o": "OCR falhou", "Nome": "OCR falhou"
        }

    data = {}

    # 1. N√∫mero GUIA
    data["N√∫mero GUIA"] = find_value_near_label(ocr_df, r'Guia\s*Principal', max_distance_x=250)

    # 2. Registro ANS
    data["Registro ANS"] = find_value_near_label(ocr_df, r'Registro\s*ANS', max_distance_x=200)

    # 3. Data de Autoriza√ß√£o
    data["Data de Autoriza√ß√£o"] = find_value_near_label(ocr_df, r'Autoriza[√ßc][√£a]o', max_distance_x=250)
    date_match = re.search(r'(\d{2}/\d{2}/\d{4})', data["Data de Autoriza√ß√£o"])
    if date_match:
        data["Data de Autoriza√ß√£o"] = date_match.group(1)

    # 4. Nome do Benefici√°rio
    data["Nome"] = find_value_near_label(ocr_df, r'10\s*-\s*Nome', max_distance_x=600)

    final_data = {
        "N√∫mero GUIA": data.get("N√∫mero GUIA", "N√£o encontrado"),
        "Registro ANS": data.get("Registro ANS", "N√£o encontrado"),
        "Data de Autoriza√ß√£o": data.get("Data de Autoriza√ß√£o", "N√£o encontrado"),
        "Nome": data.get("Nome", "N√£o encontrado"),
    }
    return final_data


# ==============================================================================
# 4Ô∏è‚É£ NOVA SE√á√ÉO: GERA√á√ÉO DE AN√ÅLISE DE FATURAMENTO (IA)
# ==============================================================================

def generate_analysis_report(df):
    """Gera um relat√≥rio em Markdown com a an√°lise dos dados extra√≠dos."""
    
    total_guias = len(df)
    if total_guias == 0:
        return "Nenhum dado para analisar."

    # C√°lculos dos KPIs
    df_pendencias = df[df.apply(lambda row: row.astype(str).str.contains('N√£o encontrado').any(), axis=1)]
    guias_com_pendencia = len(df_pendencias)
    guias_completas = total_guias - guias_com_pendencia
    percentual_sucesso = (guias_completas / total_guias) * 100 if total_guias > 0 else 0

    # An√°lise de campos com falha
    campos_faltantes = {}
    if guias_com_pendencia > 0:
        for col in df.columns:
            if col != 'Arquivo':
                faltantes = df_pendencias[col].astype(str).str.contains('N√£o encontrado').sum()
                if faltantes > 0:
                    campos_faltantes[col] = faltantes

    # Montagem do Relat√≥rio em Markdown
    report = f"""
    # üìä Relat√≥rio de An√°lise de Faturamento

    **Data da An√°lise:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}

    ---

    ## 1. Resumo Geral e Indicadores Chave (KPIs)

    | Indicador | Valor |
    | :--- | :--- |
    | üìÇ **Total de Guias Processadas** | **{total_guias}** |
    | ‚úÖ **Guias Completas (Sem pend√™ncias)** | **{guias_completas}** |
    | ‚ö†Ô∏è **Guias com Pend√™ncias (Revis√£o necess√°ria)** | **{guias_com_pendencia}** |
    | üéØ **Percentual de Sucesso da Extra√ß√£o** | **{percentual_sucesso:.2f}%** |

    ---

    ## 2. An√°lise Detalhada de Pend√™ncias
    """

    if guias_com_pendencia == 0:
        report += "\nüéâ **Excelente!** Nenhuma pend√™ncia foi identificada. Todas as guias foram processadas com sucesso."
    else:
        report += f"\nForam identificadas **{guias_com_pendencia} guias** que requerem revis√£o manual. Abaixo est√£o os detalhes:\n\n"
        report += "#### Contagem de Falhas por Campo:\n"
        for campo, contagem in campos_faltantes.items():
            report += f"- **{campo}:** {contagem} falha(s)\n"

        report += "\n#### Arquivos que Precisam de Revis√£o:\n"
        for arquivo in df_pendencias['Arquivo']:
            report += f"- `{arquivo}`\n"

    report += """
    ---

    ## 3. Recomenda√ß√µes e Pr√≥ximos Passos

    1.  **A√ß√£o Imediata:** A equipe de faturamento deve priorizar a revis√£o manual dos arquivos listados na se√ß√£o de pend√™ncias para garantir a corre√ß√£o dos dados antes do envio.
    2.  **An√°lise de Causa Raiz:** Analise os arquivos com falhas. Se o problema for a baixa qualidade da digitaliza√ß√£o, reforce os padr√µes de escaneamento. Se for um layout de guia diferente, o sistema pode precisar de ajustes.
    3.  **Processo Conclu√≠do:** Ap√≥s a corre√ß√£o manual na tabela acima, os dados est√£o prontos para serem exportados para o sistema de faturamento.
    """
    return report

# ==============================================================================
# 5Ô∏è‚É£ Gera√ß√£o de Excel e Interface (COM ADI√á√ÉO DO ANALISTA)
# ==============================================================================

def to_excel(df_to_export):
    """Converte um DataFrame para um arquivo Excel em mem√≥ria com formata√ß√£o."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df_to_export.to_excel(writer, index=False, sheet_name='Guias_Medicas')
        workbook = writer.book
        worksheet = writer.sheets['Guias_Medicas']
        header_format = workbook.add_format({
            'bold': True, 'text_wrap': True, 'valign': 'top',
            'fg_color': '#1E90FF', 'font_color': 'white', 'border': 1
        })
        for col_num, value in enumerate(df_to_export.columns.values):
            worksheet.write(0, col_num, value, header_format)
        for idx, col in enumerate(df_to_export):
            series = df_to_export[col]
            max_len = max((series.astype(str).map(len).max(), len(str(series.name)))) + 2
            worksheet.set_column(idx, idx, max_len)
    return output.getvalue()

st.title("ü§ñ Extrator de Guias M√©dicas com Analista de IA")
st.markdown("Fa√ßa o upload de guias (PDF ou Imagem). O sistema usar√° OCR e **l√≥gica espacial** para extrair os dados e um **Analista de IA** para gerar um relat√≥rio de faturamento.")

# --- BARRA LATERAL ---
with st.sidebar:
    st.image("https://i.imgur.com/3f83NC1.png", width=100)
    st.header("üì§ Upload de Arquivos")
    uploaded_files = st.file_uploader(
        "Selecione as guias (PDF, PNG, JPG)",
        type=["pdf", "png", "jpg", "jpeg"],
        accept_multiple_files=True
    )
    st.header("üõ†Ô∏è Op√ß√µes")
    show_debug_text = st.checkbox("Mostrar dados brutos do OCR (debug)")

    st.divider()

    st.header("üìñ Como Usar")
    st.markdown(
        """
        1. **Fa√ßa o upload** de um ou mais arquivos.
        2. **Aguarde** o processamento.
        3. **Revise e edite** os dados na tabela.
        4. **Clique em 'Gerar Relat√≥rio'** para uma an√°lise da IA.
        5. **Baixe os resultados** em Excel ou CSV.
        """
    )

# --- L√ìGICA PRINCIPAL DA APLICA√á√ÉO ---
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = pd.DataFrame()

if uploaded_files:
    all_data = []
    progress_bar = st.progress(0, text="Iniciando processamento...")

    for i, uploaded_file in enumerate(uploaded_files):
        file_name = uploaded_file.name
        progress_bar.progress((i + 1) / len(uploaded_files), text=f"Processando: {file_name}")
        
        ocr_dataframe = process_uploaded_file(uploaded_file)

        if not ocr_dataframe.empty:
            if show_debug_text:
                with st.expander(f"üî¨ Dados brutos do OCR de '{file_name}'"):
                    st.dataframe(ocr_dataframe)
            
            extracted_data = extract_medical_data_from_structure(ocr_dataframe)
            extracted_data["Arquivo"] = file_name
            all_data.append(extracted_data)
        else:
             st.warning(f"N√£o foi poss√≠vel extrair dados do arquivo: {file_name}")


    progress_bar.empty()

    if all_data:
        df = pd.DataFrame(all_data)[["Arquivo", "N√∫mero GUIA", "Registro ANS", "Data de Autoriza√ß√£o", "Nome"]]
        st.session_state.processed_data = df

# --- EXIBI√á√ÉO DOS RESULTADOS E DOWNLOADS ---
if not st.session_state.processed_data.empty:
    st.header("üìã Resultados Edit√°veis")
    st.markdown("Revise os dados extra√≠dos e fa√ßa as corre√ß√µes necess√°rias diretamente na tabela abaixo.")
    
    edited_df = st.data_editor(
        st.session_state.processed_data,
        num_rows="dynamic",
        use_container_width=True,
        key="data_editor"
    )

    st.header("‚¨áÔ∏è Download dos Dados Corrigidos")
    col1, col2 = st.columns(2)
    with col1:
        excel_data = to_excel(edited_df)
        timestamp = datetime.now().strftime("%Y%m%d")
        st.download_button(
            label="üì• Baixar Excel (.xlsx)", data=excel_data,
            file_name=f"guias_medicas_{timestamp}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
    with col2:
        csv_data = edited_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üìÑ Baixar CSV (.csv)", data=csv_data,
            file_name=f"guias_medicas_{timestamp}.csv",
            mime="text/csv",
            use_container_width=True
        )

    st.divider()

    # --- NOVA SE√á√ÉO DE AN√ÅLISE DE IA ---
    st.header("ü§ñ An√°lise do Faturamento (Gerada por IA)")
    st.markdown("Ap√≥s revisar os dados, clique no bot√£o abaixo para que o Analista de IA gere um relat√≥rio sobre o lote de guias.")
    
    if st.button("üîç Gerar Relat√≥rio de An√°lise", use_container_width=True, type="primary"):
        with st.spinner("O Analista de IA est√° avaliando os dados..."):
            report_md = generate_analysis_report(edited_df)
            st.markdown(report_md)

else:
    st.info("Aguardando o upload de arquivos para iniciar o processamento.")
